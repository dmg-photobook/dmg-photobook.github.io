<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>The PhotoBook Task and Dataset - Datasets</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
							<a href="index.html" class="logo">
									<span class="symbol"><img src="images/fb_logo_2.png" alt="" /></span><span class="title">The PhotoBook Task and Dataset</span>
								</a>


							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
								<li><a href="index.html">Home</a></li>
								<li><a href="datasets.html">Datasets</a></li>
								<li><a href="code_models.html">Code & Models</a></li>
								<li><a href="papers.html">Bibliography</a></li>
						</ul>
					</nav>
				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Datasets</h1>

					<ul>
						<li><a href="#intro">The full PhotoBook Dataset</a></li>
						<li><a href="#utterances">Utterance-based Reference Chains</a> </li>
						<li> <a href="#segments">Segment-based Reference Chains</a> </li>
					</ul>
<p>In the context of PhotoBook, a reference chain is a sequence of "elements" within a given game that refer to the same target image.
  We have extracted two different datasets of reference chains from the PhotoBook dialogues.</p>

<hr>


	<h2 id="intro">The PhotoBook Dataset</h2>
<!--
	<a href="#intro">Introduction</a><br />
	<a href="#dialogue_samples">Dialogue Samples</a><br />
	<a href="#architecture">Dataset Architecture</a><br />
	<a href="#processor">Dataset Processor</a><br />
	<a href="#visualisation">Visualisation</a><br />
	<a href="#download">Download</a>
-->
						<p>The PhotoBook Dataset was collected using a dedicated conversation task called the PhotoBook Task.
							In the PhotoBook task, two participants are paired for an online multi-round image identification game.
							In this game they are  shown collections of images which resemble the page of a photo book.
							Each of these collections is a randomly ordered grid of six similar images depicting
							everyday scenes extracted from the MS COCO Dataset.
							On each page of the photo book, some of the images are present in the displays of both participants
							(the <i>common images</i>). The other images are each shown to one of the participants only (the <i>different images</i>).
							Three of the images in each display are highlighted through a yellow bar under the picture.
							The participants are tasked to mark these highlighted  target images as either <i>common</i> or <i>different</i>
							by chatting with their partner. A full game consists of five consecutive rounds,
							where some of the previously displayed images will re-appear in later rounds,
							prompting participants to re-refer to them multiple times.
		For a detailed account of the dataset and data collection process, see our papers
		<a href="https://arxiv.org/abs/1906.01530" target="_blank"><b>The PhotoBook Dataset: Building Common Ground through Visually Grounded Dialogue</b></a>
		and
		<a href="https://esc.fnwi.uva.nl/thesis/centraal/files/f738860517.pdf" target="_blank"><b>How should we call it? - Introducing the PhotoBook Conversation Task and Dataset for Training Natural Referring Expression Generation in Artificial Dialogue Agents</b>.</a>
		Further details can be found on the <a href="pb_dataset.html">dataset information page</a>. You can also visually browse the dataset from <a href="https://lang.science.uva.nl/photobook/domain/games">this</a> website! </p>


<!--
<h2 id="download">Download</h2>

The PhotoBook Dataset can be cloned from the Github repository at <a href="https://github.com/dmg-photobook/photobook_dataset" target="_blank">https://github.com/dmg-photobook/photobook_dataset</a>.<br /><br />

<b>Alternatively, the files can be downloaded directly by clicking the following links:</b><br /><br />
-->
<a href="https://github.com/dmg-photobook/photobook_dataset/raw/master/logs.zip" target="_blank">Download the PhotoBook log files</a> (zip-compressed, 8MB)<br /><br />

<a href="https://github.com/dmg-photobook/photobook_dataset/raw/master/images.zip" target="_blank">Download the PhotoBook image sets</a> (zip-compressed, 60MB)<br /><br />
<!--							
<a href="https://raw.githubusercontent.com/dmg-photobook/photobook_dataset/master/processor.py" target="_blank">Download the PhotoBook processor</a> (Python class, 5kB)<br /><br />
-->
						
<hr>

<h2 id="utterances">Utterance-based Reference Chains</h2>

              <p>
		      In PhotoBook, participants can freely interact via chat so the dialogues include different types of dialogue act.
                In our paper <b><a href="">Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts</a></b>, we concentrate
                on a specific type of dialogue contribution, referring utterances. From each PhotoBook game between two specific participants,
                we automatically extract all the key messages that contain an image description referring to a given image target.
                The extraction procedure is described in the paper and the corresponding code is on our <a href="https://github.com/dmg-photobook/ref-gen-photobook/tree/main/chain-extraction">GitHub repository</a>.
                The result of this procedure is a new dataset of reference chains made up of 16,525 reference chains and a total of 41,340 referring utterances. 
		You can visually browse through the reference chains on <a href="https://lang.science.uva.nl/photobook/domain/images2">this</a> website. </p>
                Contact <a href="https://glnmario.github.io">Mario Giulianelli</a> if you have any questions.
              </p>
	      <p>
			  <b>Version 2</b>: Download the most recent version of the utterance-based reference chains: <a href="https://github.com/dmg-photobook/ref-gen-photobook/blob/main/dataset/v2.zip?raw=true"><b>v2</b></a> <br />

			  In v2, we replaced the words that were erroneously censored in the original PB dataset with their correct spelling (e.g. gla**es -> glasses), we corrected the most frequent typos, and we added a few words to SpaCy's stop-word list. <br /><br/>

			  <b>Version 1</b>: To reproduce the results presented in the <i>Refer, Reuse, Reduce</i> paper, please download <a href="https://github.com/dmg-photobook/ref-gen-photobook/blob/main/dataset/v1.zip?raw=true"><b>v1</b></a>. All the models reported in this paper were trained/validated/tested on the first version of the utterance-based PB dataset. <br /> <br />
	      </p>	

<hr>
<h2 id="segments">Segment-based Reference Chains</h2>

<p>In our paper <b><a href="https://www.aclweb.org/anthology/P19-1184/">The PhotoBook Dataset: Building Common Ground through Visually Grounded Dialogue</a></b>,
  we propose a simple procedure to automatically extract reference chains made up of dialogue segments.
  A dialogue segment is defined as a collection of consecutive utterances that, as a whole, discuss a given
  target image and include expressions referring to it. The documented segment chain dataset creator can be downloaded from this <a href="https://github.com/dmg-photobook/photobook_dataset/tree/master/segmentation" target="_blank">GitHub repository</a>
<!--or as a zipped archive <a href="https://github.com/dmg-photobook/photobook_dataset/raw/master/segmentation.zip" target="_blank">here</a>. -->
(to execute the files, place the <code>logs</code> folder into the project's <code>data</code> folder). On this <a href="reference_chains.html">dataset information page</a> you can find sample segment chains and relevant statistics of the segment chains dataset, as well as 
	additional information about the segmentation heuristics and their evaluation and validation. You can also visually browse through the reference chains on <a href="https://lang.science.uva.nl/photobook/domain/images">this</a> website. </p>

<p><a href="https://github.com/dmg-photobook/photobook_dataset/raw/master/reference_chain_data.zip">Download the segment-based reference chains</a> that were used in training/validating/testing the models reported in the paper that introduced the PhotoBook dataset.

						</div>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<section>
								<h2>Contact</h2>
								<ul class="icons">
									<li> For questions and remarks about this website or the PhotoBook Task and Dataset, please contact <a href="mailto:j.haber@qmul.ac.uk"> Janosch Haber</li>
									<li> <a href="https://github.com/dmg-photobook/photobook_dataset.git" class="icon style2 fa-github"><span class="label">GitHub</span></a></li>
								</ul>
								Raquel Fern√°ndez<br />
     							Science Park 107, office F1.07 <br />
     							+31 (0)20 525 7009  <br />
							</section>
							<section>


							</section>
							<ul class="copyright">
								<li>&copy; Dialogue Modeling Group, University of Amsterdaom. All rights reserved</li><li>Design: <a href="http://html5up.net" target="_blank">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
